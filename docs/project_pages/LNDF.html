<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LNDF</title>
  <link rel="stylesheet" href="/stylesheet.css">
  <link rel="shortcut icon" type="image/x-icon" href="/resources/favicon.ico">
  <link rel="stylesheet" href="/professional.css" id="aux_style">
  <script>
      if (window.sessionStorage.getItem('style_mode') == 'fun') {
          document.getElementById('aux_style').setAttribute('href', '');
      }
  </script>
</head scroll=no>

<body>

  <div class="content" id="content">
    <div class="header">
      <img src="/resources/icra_2023_web_smol.gif" class="project_picture">
      <h1 class="project_page_title">
        Local Neural Descriptor Fields: Locally Conditioned Object Representations for Manipulation
      </h1>
      <a href="/index.html">Home</a>
    </div>
      <p>
        Abstract— A robot operating in a household environment will
        see a wide range of unique and unfamiliar objects. While a
        system could train on many of these, it is infeasible to predict
        all the objects a robot will see. In this paper, we present a
        method to generalize object manipulation skills acquired from
        a limited number of demonstrations, to novel objects from
        unseen shape categories. Our approach, Local Neural Descriptor
        Fields (L-NDF), utilizes neural descriptors defined on the local
        geometry of the object to effectively transfer manipulation
        demonstrations to novel objects at test time. In doing so, we
        leverage the local geometry shared between objects to produce a
        more general manipulation framework. We illustrate the efficacy
        of our approach in manipulating novel objects in novel poses –
        both in simulation and in the real world.
      </p>

      <p>
        Please see the <a href="https://github.com/elchun/ndf_robot/tree/conv_occ" target="_blank">Github</a> for
        code and additional information.  (Github is not fully polished but all essentials are there).
      </p>


      <h1>Video</h1>
      <h1>Paper</h1>
      This work has been accepted to ICRA 2023, video and paper will be updated soon!!!
  </div>


</body>
</html>
